---
title: "7302c CUTe"
author: "Amar Rao"
date: "December 14, 2017"
output: 
  html_document:
    toc: true
    toc_float:
      collapsed: false
    theme: united
    highlight: tang
    fig_width: 7
    fig_height: 6
    fig_caption: true
    code_folding: hide

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

#clear all environment and session variables
rm(list = ls(all = TRUE))


```


Libraries
```{r}

library(knitr)
library(tidyverse)
library(lubridate)
library(caret)
library(DMwR)
library(forecast)
library(lubridate)
library(imputeTS)
library(TTR)
library(graphics)
library(zoo)
```

## Reading data

* set working directory
```{r}
setwd('/home/amar/classes/INSOFE_Batch35_7302c_CUTe_Team17')

```

### Load the data set

```{r}
fin_data_orig <- read.csv('Datasets/train_data.csv', header = TRUE, sep = ',', na.strings = "", colClasses = "double", numerals = "no.loss")
str(fin_data_orig, list.len = ncol(fin_data_orig))
head(fin_data_orig)
```

* We know y2 is a binary column. converting that to factor.

```{r}
cat_attrs <- c('y2')
num_attrs <- setdiff(colnames(fin_data_orig), cat_attrs)

fin_data_orig[cat_attrs] <- data.frame(sapply(fin_data_orig[cat_attrs], as.factor))
str(fin_data_orig, list.len = ncol(fin_data_orig))
```

```{r}
summary(fin_data_orig)
```


###Observations:

* There're 109 regressors and 2 target variables (y1 and y2) and 1769 observations
* Data appears to already have been scaled and standardized. 
* There are a few empty columns (ie all rows are blank in these columns )
* Some values are missing in other columns
* Timestamp starts as a day number at 14 and goes up to 1782 days (1769 days in total)



## Preprocessing
### Empty Columns

  * Following columns are completely blank (column with all NA values) in the data frame.

```{r}
emptycols <- colnames(fin_data_orig[,sapply(fin_data_orig, function(x) { all(is.na(x))})])
emptycols
```

*Removing these columns

```{r}
fin_data <- fin_data_orig[, sapply(fin_data_orig, function(x) { !all(is.na(x))})]
```

### Handle NAs

* Checking how spread the NAs are in other columns
```{r}
colswithna <- colSums(is.na(fin_data))

sort(colswithna, decreasing = TRUE)

```

#### The following columns have very large number of NAs so imputing those would make the data diluted.

*f_63
*f_27
*f_3
*f_28
*f_31
*f_35
*f_25
*f_17

####So removing those columns. Will use knnImputation for the rest once I do the test-train split.

```{r}
fin_data <- subset(fin_data,select = -c(f_63, f_27, f_3, f_28, f_31, f_35, f_25, f_17))

```

### convert timestamp to date
* The timestamps are given as day numbers starting with 14. We have observations for 1769 days (approx 4.8 years of data)

* Generating dates from 2012 and setting that as the id columns
```{r}
origindate <- as.Date('2011-12-31', format = '%Y-%m-%d')
origindate
fin_data$timestamp = as.Date(fin_data$timestamp, origindate)
rownames(fin_data) <- fin_data$timestamp

#removing timestamp column
fin_data$timestamp <- NULL
head(fin_data)
tail(fin_data)
```

* checking if there're any sparse columns (ie columns with very large number of zeros)

```{r}
sort(colSums(fin_data == 0), decreasing = TRUE)

```

* from the above we can see that t_10, t_13, t_30, t_20 all have very large number of 0s. Checking to see if these are factors

```{r}
tail(fin_data$t_10, 200)
tail(fin_data$t_13, 200)
tail(fin_data$t_30, 200)
tail(fin_data$t_20, 100)
```

* from looking at the data in these tables, it is clear that these are not factors.
* since these have very large number of zeros, they cannot have any meaningful impact on the target variables. So removing them.

```{r}
fin_data <- subset(fin_data, select = -c(t_10, t_13, t_30, t_20))


```
* The target variable y1 is a percent change. Will use another column to get a price so that
* it is easier to see trend and forecast
```{r}

setdailyprice <- function(daily_price) {
  retprice <- daily_price
  for(i in 1:length(daily_price)) {
    if (i == 1) {
      retprice[i] = 1000
    } else {
      retprice[i] = retprice[i-1]*(1+ daily_price[i])
    }

  }
  return(retprice)
}

fin_data$DailyPrice <- setdailyprice(fin_data$y1)
head(fin_data)


```






### Train-test split

```{r}

fin_train <- fin_data[rownames(fin_data) <= as.Date('2014-12-31', format = '%Y-%m-%d'), ]

fin_test <- fin_data[rownames(fin_data) > as.Date('2014-12-31', format = '%Y-%m-%d'), ]

```

###Imputation and scaling

```{r}

library(RANN)
set.seed(1234)
preproc_preds <- preProcess(x = subset(fin_train, select = -c(y1, y2)), method = c("knnImpute"))

fin_train <- predict(object = preproc_preds, fin_train)
fin_test <- predict(object = preproc_preds, fin_test)
sum(is.na(fin_train))
sum(is.na(fin_test))

```

## Assessing fit for Timeseries Forecasting
* Need to check if y1 exhibits strong trend and some seasonality (optionally). If so, we can proceed with timeseries forecasting.



```{r}
y1ts <- ts(fin_train$y1, start = c(2012, 1,1), frequency = 365.25)
plot(y1ts,
     type="l",
     lwd=2,
     col="blue",
     xlab="Daily",
     ylab="Change",
     main="Time series plot for stock - for target variable y1")
```

```{r}
y1decomp <- decompose(x = y1ts)
plot(y1decomp)
```

###Observations:
* We see that there's a pronounced trend
* Seasonality at daily frequency doesn't seem to exist. 
* To see if there's a seasonality at all, taking weekly average first (then monthly average)
* and decomposing.

```{r}
fin_train$Year <- as.numeric(year(rownames(fin_train)))
fin_train$Month <- as.numeric(month(rownames(fin_train)))
fin_train$WeekOfYear <- isoweek(rownames(fin_train))

fin_train_weekly <- fin_train %>% group_by(Year, Month, WeekOfYear) %>% summarize("WeeklyAvgY1" = mean(y1))
fin_train_monthly <- fin_train %>% group_by(Year, Month) %>% summarize("MonthlyAvgY1" = mean(y1))

```


```{r}


weeklyy1ts <- ts(fin_train_weekly$WeeklyAvgY1, start = c(2012, 1,1), frequency = 52)
plot(decompose(weeklyy1ts))
```


```{r}
monthlyy1ts <- ts(fin_train_monthly$MonthlyAvgY1, start = c(2012, 1,1), frequency = 12)
plot(decompose(monthlyy1ts))
```

### Observations:
Based on the above, it is clear that there's no clear seasonality that affects the daily percent change in the value of y1. Consequently will not do a Seasonal TS forecasting

```{r}
#Cleaning up Year, Month, and WeekOfYear column as we won't need that.

fin_train$Year = NULL
fin_train$Month = NULL
fin_train$WeekOfYear = NULL

```





## Initial Model
* For this, we need to first create a matrix of all regressors

```{r}
library(Matrix)
fin_x_reg <- subset(fin_train, select = -c(y1, y2))

nrow(fin_x_reg)
ncol(fin_x_reg)
rankMatrix(fin_x_reg)
```


* Rank of the matrix (87) is less than the number of columns. This will cause errors running Arima or auto.arima. So need to eliminate that.

```{r}

names(fin_train[, sapply(fin_train, function(v) var(v, na.rm=TRUE)==0)])
for(col in names(fin_data)) {
  if (is.constant(fin_data[, col])) {
    print(col)
  }
}
```

* Will exclude these columns for further analysis

```{r}
fin_train <- subset(fin_train, select = -c(t_9, t_16, t_22))
fin_test <- subset(fin_test, select = -c(t_9, t_16, t_22))


ncol(subset(fin_train, select = -c(y1, y2)))
#confirming if that fixes the rank issue
rankMatrix(as.matrix(subset(fin_train, select = -c(y1, y2))))
```

* Trying StepAIC to identify significant regressors

* now creating separate dataframes for y1 and y2

```{r}

y1_train <- subset(fin_train, select = -y2)
y1_test <- subset(fin_test, select = -y2)
y2_train <- subset(fin_train, select = -y1)
y2_test <- subset(fin_test, select = -y1)


```

```{r}


base_linreg <- lm(y1 ~ ., data = y1_train)
base_linreg
```

* since there are several variables, using stepAIC to see if we can reduce the number of coefficients keeping significant ones


```{r}

ols_all_preds <- predict(base_linreg, y1_test)

print('Error metrics for Train data')
print(regr.eval(ols_all_preds, y1_train$y1))
print("")
print('Error metrics for Test data')
print(regr.eval(ols_all_preds, y1_test$y1))
```

```{r}
library(MASS)
stepAIC(base_linreg, direction = "both")
```


####Based on stepAIC, will use only the following regressors:

d_0, d_1, d_2, d_3, d_4, f_0, f_5, f_7, f_8, f_9, f_11, f_13, f_14, f_15, f_16, f_18,  f_19, f_20 , f_22 , f_23 , f_24 , f_29 , f_30 , f_32 , f_33 , f_34 , f_36 , f_37 , f_39 , f_40 , f_41 , f_42 , f_43 , f_44 , f_46 , f_48 , f_49 , f_50 , f_51 , f_52 , f_53 , f_54 , f_56 , f_58 , f_59 , f_60 , f_62 , t_0 , t_2 , t_3 , t_6 , t_7 , t_11 , t_12 , t_14 , t_17 , t_18 , t_19 , t_21 , t_24 , t_25 , t_27 , t_29 , t_32 , t_33 , t_34 , t_35 , t_36 , t_37 , t_38 , t_39 , t_40 , t_43 , t_44
    
    
```{r}
aic_rec_mdl <- lm(formula = y1 ~ d_0 + d_1 + d_2 + d_3 + d_4 + f_0 + f_5 + f_7 + 
    f_8 + f_9 + f_11 + f_13 + f_14 + f_15 + f_16 + f_18 + f_19 + 
    f_20 + f_22 + f_23 + f_24 + f_29 + f_30 + f_32 + f_33 + f_34 + 
    f_36 + f_37 + f_39 + f_40 + f_41 + f_42 + f_43 + f_44 + f_46 + 
    f_48 + f_49 + f_50 + f_51 + f_52 + f_53 + f_54 + f_56 + f_58 + 
    f_59 + f_60 + f_62 + t_0 + t_2 + t_3 + t_6 + t_7 + t_11 + 
    t_12 + t_14 + t_17 + t_18 + t_19 + t_21 + t_24 + t_25 + t_27 + 
    t_29 + t_32 + t_33 + t_34 + t_35 + t_36 + t_37 + t_38 + t_39 + 
    t_40 + t_43 + t_44, data = y1_train)


aic_rec_mdl
```

```{r}
aic_preds <- predict(aic_rec_mdl, y1_test)

regr.eval(aic_preds, y1_train$y1)
regr.eval(aic_preds, y1_test$y1)

```

```{r}
library(glmnet)
set.seed(1234)

names(y1_train)
cv_lasso <- cv.glmnet(as.matrix(subset(y1_train, select = -y1)), as.matrix(y1_train$y1), alpha = 1, type.measure = "mae", nfolds = 4)
plot(cv_lasso)
plot(cv_lasso$glmnet.fit, xvar = 'lambda', label = TRUE)

lasso_1 <- glmnet(x = as.matrix(subset(y1_train, select = -y1)), y = as.matrix(y1_train$y1), alpha = 1, lambda = cv_lasso$lambda.min)

lasso_1_preds <- predict(lasso_1, as.matrix(subset(y1_test, select = -y1)))
regr.eval(lasso_1_preds, y1_test$y1)

X_train = as.matrix(subset(y1_train, select= c(d_0, d_1, d_2, d_3, d_4, f_0, f_5, f_7, f_8, f_9, f_11, f_13, f_14, f_15, f_16, f_18,  f_19, f_20 , f_22 , f_23 , f_24 , f_29 , f_30 , f_32 , f_33 , f_34 , f_36 , f_37 , f_39 , f_40 , f_41 , f_42 , f_43 , f_44 , f_46 , f_48 , f_49 , f_50 , f_51 , f_52 , f_53 , f_54 , f_56 , f_58 , f_59 , f_60 , f_62 , t_0 , t_2 , t_3 , t_6 , t_7 , t_11 , t_12 , t_14 , t_17 , t_18 , t_19 , t_21 , t_24 , t_25 , t_27 , t_29 , t_32 , t_33 , t_34 , t_35 , t_36 , t_37 , t_38 , t_39 , t_40 , t_43 , t_44)))

X_test = as.matrix(subset(y1_test, select= c(d_0, d_1, d_2, d_3, d_4, f_0, f_5, f_7, f_8, f_9, f_11, f_13, f_14, f_15, f_16, f_18,  f_19, f_20 , f_22 , f_23 , f_24 , f_29 , f_30 , f_32 , f_33 , f_34 , f_36 , f_37 , f_39 , f_40 , f_41 , f_42 , f_43 , f_44 , f_46 , f_48 , f_49 , f_50 , f_51 , f_52 , f_53 , f_54 , f_56 , f_58 , f_59 , f_60 , f_62 , t_0 , t_2 , t_3 , t_6 , t_7 , t_11 , t_12 , t_14 , t_17 , t_18 , t_19 , t_21 , t_24 , t_25 , t_27 , t_29 , t_32 , t_33 , t_34 , t_35 , t_36 , t_37 , t_38 , t_39 , t_40 , t_43 , t_44)))
cv_lasso_1 <- cv.glmnet(X_train, as.matrix(y1_train$y1), alpha = 1, type.measure = "mse", nfolds = 4)
plot(cv_lasso_1)

cv_lasso_2 <- glmnet(X_train, as.matrix(y1_train$y1), lambda = cv_lasso_1$lambda.min, alpha = 1)

cv_lasso_2_preds <- predict(cv_lasso_2, X_test)

regr.eval(cv_lasso_2_preds, y1_test$y1)

```

#### Assessing the colinearity

```{r}
library(car)
vif(mod = base_linreg)

library('corrplot')


corrplot(cor(subset(y1_train, select= c(d_0, d_1, d_2, d_3, d_4, f_0, f_5, f_7, f_8, f_9, f_11, f_13, f_14, f_15, f_16, f_18,  f_19, f_20 , f_22 , f_23 , f_24 , f_29 , f_30 , f_32 , f_33 , f_34 , f_36 , f_37 , f_39 , f_40 , f_41 , f_42 , f_43 , f_44 , f_46 , f_48 , f_49 , f_50 , f_51 , f_52 , f_53 , f_54 , f_56 , f_58 , f_59 , f_60 , f_62 , t_0 , t_2 , t_3 , t_6 , t_7 , t_11 , t_12 , t_14 , t_17 , t_18 , t_19 , t_21 , t_24 , t_25 , t_27 , t_29 , t_32 , t_33 , t_34 , t_35 , t_36 , t_37 , t_38 , t_39 , t_40 , t_43 , t_44)), use = "complete.obs"), method = "number")

```


* checking if we need to stationarize
```{r}

acf(y1ts)
pacf(y1ts)

ndiffs(y1ts)

```

* No need to difference as the variance seems to be stationary.

```{r}

arima2 <- Arima(y = y1ts, order = c(2,0,0), xreg = subset(y1_train, select= c(d_0, d_1, d_2, d_3, d_4, f_0, f_5, f_7, f_8, f_9, f_11, f_13, f_14, f_15, f_16, f_18,  f_19, f_20 , f_22 , f_23 , f_24 , f_29 , f_30 , f_32 , f_33 , f_34 , f_36 , f_37 , f_39 , f_40 , f_41 , f_42 , f_43 , f_44 , f_46 , f_48 , f_49 , f_50 , f_51 , f_52 , f_53 , f_54 , f_56 , f_58 , f_59 , f_60 , f_62 , t_0 , t_2 , t_3 , t_6 , t_7 , t_11 , t_12 , t_14 , t_17 , t_18 , t_19 , t_21 , t_24 , t_25 , t_27 , t_29 , t_32 , t_33 , t_34 , t_35 , t_36 , t_37 , t_38 , t_39 , t_40 , t_43 , t_44)), include.drift = TRUE)

arima1 <- Arima(y = y1ts, order = c(2,0,1))


arima1_preds <- forecast(object = arima1, h = nrow(y1_test))
accuracy(arima1_preds,y1_test$y1)

plot(arima1_preds)



fin_arima1 <- auto.arima(y1ts, xreg = subset(y1_train, select= c(d_0, d_1, d_2, d_3, d_4, f_0, f_5, f_7, f_8, f_9, f_11, f_13, f_14, f_15, f_16, f_18,  f_19, f_20 , f_22 , f_23 , f_24 , f_29 , f_30 , f_32 , f_33 , f_34 , f_36 , f_37 , f_39 , f_40 , f_41 , f_42 , f_43 , f_44 , f_46 , f_48 , f_49 , f_50 , f_51 , f_52 , f_53 , f_54 , f_56 , f_58 , f_59 , f_60 , f_62 , t_0 , t_2 , t_3 , t_6 , t_7 , t_11 , t_12 , t_14 , t_17 , t_18 , t_19 , t_21 , t_24 , t_25 , t_27 , t_29 , t_32 , t_33 , t_34 , t_35 , t_36 , t_37 , t_38 , t_39 , t_40 , t_43 , t_44)), allowdrift = TRUE)
fin_arima1
```


```{r}
auto_arima_preds <- forecast(object = fin_arima1, h = nrow(y1_test), xreg = subset(y1_train, select= c(d_0, d_1, d_2, d_3, d_4, f_0, f_5, f_7, f_8, f_9, f_11, f_13, f_14, f_15, f_16, f_18,  f_19, f_20 , f_22 , f_23 , f_24 , f_29 , f_30 , f_32 , f_33 , f_34 , f_36 , f_37 , f_39 , f_40 , f_41 , f_42 , f_43 , f_44 , f_46 , f_48 , f_49 , f_50 , f_51 , f_52 , f_53 , f_54 , f_56 , f_58 , f_59 , f_60 , f_62 , t_0 , t_2 , t_3 , t_6 , t_7 , t_11 , t_12 , t_14 , t_17 , t_18 , t_19 , t_21 , t_24 , t_25 , t_27 , t_29 , t_32 , t_33 , t_34 , t_35 , t_36 , t_37 , t_38 , t_39 , t_40 , t_43 , t_44)))
accuracy(auto_arima_preds, y1_test$y1)

```


## Final Model
## Predictions
## Performance

