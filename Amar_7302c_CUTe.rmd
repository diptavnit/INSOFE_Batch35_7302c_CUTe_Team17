---
title: "7302c CUTe"
author: "Amar Rao"
date: "December 14, 2017"
output: 
  html_document:
    toc: true
    toc_float:
      collapsed: false
    theme: united
    highlight: tang
    fig_width: 7
    fig_height: 6
    fig_caption: true
    code_folding: hide

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

#clear all environment and session variables
rm(list = ls(all = TRUE))


```


Libraries
```{r}

library(knitr)
library(tidyverse)
library(lubridate)
library(caret)
library(DMwR)
library(forecast)
library(lubridate)
library(imputeTS)
library(TTR)
library(graphics)
library(zoo)
```

## Reading data

* set working directory
```{r}
setwd('/home/amar/classes/INSOFE_Batch35_7302c_CUTe_Team17')

```

### Load the data set

```{r}
fin_data_orig <- read.csv('Datasets/train_data.csv', header = TRUE, sep = ',', na.strings = "", colClasses = "double", numerals = "no.loss")
str(fin_data_orig, list.len = ncol(fin_data_orig))
head(fin_data_orig)
```

* We know y2 is a binary column. converting that to factor.

```{r}
cat_attrs <- c('y2')
num_attrs <- setdiff(colnames(fin_data_orig), cat_attrs)
num_attrs

fin_data_orig[cat_attrs] <- data.frame(sapply(fin_data_orig[cat_attrs], as.factor))
str(fin_data_orig, list.len = ncol(fin_data_orig))
```

```{r}
summary(fin_data_orig)
```


###Observations:

* There're 109 regressors and 2 target variables (y1 and y2) and 1769 observations
* Data appears to already have been scaled and standardized. 
* There are a few empty columns (ie all rows are blank in these columns )
* Some values are missing in other columns
* Timestamp starts as a day number at 14 and goes up to 1782 days (1769 days in total)



## Preprocessing
### Empty Columns

  * Following columns are completely blank in the data frame.

```{r}
emptycols <- colnames(fin_data_orig[,sapply(fin_data_orig, function(x) { all(is.na(x))})])
emptycols
```

*Removing these columns

```{r}
fin_data <- fin_data_orig[, sapply(fin_data_orig, function(x) { !all(is.na(x))})]
```

### Handle NAs

* Checking how spread the NAs are in other columns
```{r}
colswithna <- colSums(is.na(fin_data))

sort(colswithna, decreasing = TRUE)

```

#### The following columns have very large number of NAs so imputing those would make the data diluted.

*f_63
*f_27
*f_3
*f_28
*f_31
*f_35
*f_25
*f_17

####So removing those columns. Will use knnImputation for the rest once I do the test-train split.

```{r}
fin_data <- subset(fin_data,select = -c(f_63, f_27, f_3, f_28, f_31, f_35, f_25, f_17))

```

### convert timestamp to date
* The timestamps are given as day numbers starting with 14. We have observations for 1782 days = 4.88 years of data. 
* Generating dates from 2013
```{r}
origindate <- as.Date('2011-12-31', format = '%Y-%m-%d')
origindate
fin_data$timestamp = as.Date(fin_data$timestamp, origindate)

head(fin_data)
tail(fin_data)
```

### Train-test split

```{r}
fin_train <- fin_data[which(fin_data$timestamp <= as.Date('2014-12-31', format = '%Y-%m-%d')), ]
fin_test <- fin_data[which(fin_data$timestamp > as.Date('2014-12-31', format = '%Y-%m-%d')), ]

```

###Imputation

```{r}
preproc_preds <- preProcess(x = select(fin_train, -timestamp, -y1, -y2), method = c("center", "scale", "knnImpute"))

fin_train <- predict(object = preproc_preds, fin_train)
fin_test <- predict(object = preproc_preds, fin_test)
sum(is.na(fin_train))
sum(is.na(fin_test))

```

## Assessing fit for Timeseries Forecasting
* Need to check if y1 exhibits strong trend and some seasonality. If so, we can proceed with timeseries forecasting.



```{r}
y1ts <- ts(fin_train$y1, start = c(2012, 1,1), frequency = 365.25)
plot(y1ts,
     type="l",
     lwd=2,
     col="blue",
     xlab="Daily",
     ylab="Change",
     main="Time series plot for stock - for target variable y1")
```

```{r}
y1decomp <- decompose(x = y1ts)
plot(y1decomp)
```

###Observations:
* We see that there's a pronounced trend
* Seasonality at daily frequency doesn't seem to exist. 
* To see if there's a seasonality at all, taking weekly average first (then monthly average)
* and decomposing.

```{r}
fin_train$Year <- as.numeric(year(fin_train$timestamp))
fin_train$Month <- as.numeric(month(fin_train$timestamp))
fin_train$WeekOfYear <- isoweek(fin_train$timestamp)

fin_train_weekly <- fin_train %>% group_by(Year, Month, WeekOfYear) %>% summarize("WeeklyAvgY1" = mean(y1))
fin_train_monthly <- fin_train %>% group_by(Year, Month) %>% summarize("MonthlyAvgY1" = mean(y1))

```


```{r}


weeklyy1ts <- ts(fin_train_weekly$WeeklyAvgY1, start = c(2012, 1,1), frequency = 52)
plot(decompose(weeklyy1ts))
```


```{r}
monthlyy1ts <- ts(fin_train_monthly$MonthlyAvgY1, start = c(2012, 1,1), frequency = 12)
plot(decompose(monthlyy1ts))
```

### Observations:
Based on the above, it is clear that there's no clear seasonality that affects the daily percent change in the value of y1. Consequently will not do a Seasonal TS forecasting

```{r}
#Cleaning up Year, Month, and WeekOfYear column as we won't need that.

fin_train$Year = NULL
fin_train$Month = NULL
fin_train$WeekOfYear = NULL

```





## Initial Model
* For this, we need to first create a matrix of all regressors

```{r}
fin_x_reg <- as.matrix(select(fin_train, -y1, -y2, -timestamp))
library(Matrix)

nrow(fin_x_reg)
ncol(fin_x_reg)
rankMatrix(fin_x_reg)
```


* Rank of the matrix (90) is less than the number of columns. This caused errors running Arima or auto.arima.
* Trying StepAIC to identify significant regressors

```{r}

str(fin_train)
fin_train_y1 <- dplyr::select(fin_train, -timestamp, -y2)
summary(fin_train_y1)
base_linreg <- lm(y1 ~ ., data = select(fin_train, -timestamp, -y2))
base_linreg
```

```{r}
library(MASS)
stepAIC(base_linreg, direction = "both")
```


* Based on PACF, setting a P of 4.

* checking if we need to stationarize
```{r}

acf(y1ts)
pacf(y1ts)

ndiffs(y1ts)

```

* No need to difference as the variance seems to be stationary.

```{r}

fin_arima1 <- auto.arima(y1ts, xreg = select(fin_train, -timestamp, -y1, -y2), )

```


## Final Model
## Predictions
## Performance

